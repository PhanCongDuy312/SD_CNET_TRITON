{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tritonclient.http\n",
    "from diffusers.utils import load_image\n",
    "from PIL import Image\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "model_name = \"stable_diffusion_cnet_bls\"\n",
    "url = \"0.0.0.0:8000\"\n",
    "model_version = \"1\"\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = load_image(\n",
    "    \"./input_image_vermeer.png\"\n",
    ")\n",
    "\n",
    "image = np.array(image)\n",
    "\n",
    "low_threshold = 100\n",
    "high_threshold = 200\n",
    "\n",
    "image = cv2.Canny(image, low_threshold, high_threshold)\n",
    "image = image[:, :, None]\n",
    "image = np.concatenate([image, image, image], axis=2)\n",
    "canny_image = Image.fromarray(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model input params\n",
    "prompt = \"A Corgi is flying in the red sky\"\n",
    "negative_prompt = \"bad quality\"\n",
    "samples = 1 \n",
    "scheduler = \"PNDMScheduler\"\n",
    "steps = 20\n",
    "guidance_scale = 7.5\n",
    "seed = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triton_client = tritonclient.http.InferenceServerClient(url=url, verbose=False)\n",
    "assert triton_client.is_model_ready(\n",
    "    model_name=model_name, model_version=model_version\n",
    "), f\"model {model_name} not yet ready\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input placeholder\n",
    "prompt_in = tritonclient.http.InferInput(name=\"PROMPT\", shape=(batch_size,), datatype=\"BYTES\")\n",
    "negative_prompt_in = tritonclient.http.InferInput(name=\"NEGATIVE_PROMPT\", shape=(batch_size,), datatype=\"BYTES\")\n",
    "pose_image = tritonclient.http.InferInput(\"POSE_IMAGE\", canny_image.shape, \"FP32\")\n",
    "scheduler_in = tritonclient.http.InferInput(name=\"SCHEDULER\", shape=(batch_size,), datatype=\"BYTES\")\n",
    "steps_in = tritonclient.http.InferInput(\"STEPS\", (batch_size, ), \"INT32\")\n",
    "guidance_scale_in = tritonclient.http.InferInput(\"GUIDANCE_SCALE\", (batch_size, ), \"FP32\")\n",
    "seed_in = tritonclient.http.InferInput(\"SEED\", (batch_size, ), \"INT64\")\n",
    "\n",
    "images = tritonclient.http.InferRequestedOutput(name=\"IMAGES\", binary_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_in.set_data_from_numpy(np.asarray([prompt] * batch_size, dtype=object))\n",
    "negative_prompt_in.set_data_from_numpy(np.asarray([negative_prompt] * batch_size, dtype=object))\n",
    "pose_image.set_data_from_numpy(np.asarray([samples], dtype=np.int32))\n",
    "scheduler_in.set_data_from_numpy(np.asarray([scheduler] * batch_size, dtype=object))\n",
    "steps_in.set_data_from_numpy(np.asarray([steps], dtype=np.int32))\n",
    "guidance_scale_in.set_data_from_numpy(np.asarray([guidance_scale], dtype=np.float32))\n",
    "seed_in.set_data_from_numpy(np.asarray([seed], dtype=np.int64))\n",
    "\n",
    "response = triton_client.infer(\n",
    "    model_name=model_name, model_version=model_version, \n",
    "    inputs=[prompt_in,negative_prompt_in,pose_image,scheduler_in,steps_in,guidance_scale_in,seed_in], \n",
    "    outputs=[images]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = response.as_numpy(\"IMAGES\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "if images.ndim == 3:\n",
    "    images = images[None, ...]\n",
    "images = (images * 255).round().astype(\"uint8\")\n",
    "pil_images = [Image.fromarray(image) for image in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_grid(imgs, rows, cols):\n",
    "    assert len(imgs) == rows*cols\n",
    "\n",
    "    w, h = imgs[0].size\n",
    "    grid = Image.new('RGB', size=(cols*w, rows*h))\n",
    "    grid_w, grid_h = grid.size\n",
    "    \n",
    "    for i, img in enumerate(imgs):\n",
    "        grid.paste(img, box=(i%cols*w, i//cols*h))\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = 1 # change according to no.of samples \n",
    "cols = 1 # change according to no.of samples\n",
    "# rows * cols == no.of samples\n",
    "image_grid(pil_images, rows, cols)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
